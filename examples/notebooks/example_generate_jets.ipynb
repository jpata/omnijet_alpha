{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import gabbro.plotting.utils as plot_utils\n",
    "from gabbro.metrics.jet_substructure import JetSubstructure\n",
    "from gabbro.plotting.feature_plotting import plot_features\n",
    "from gabbro.utils.arrays import ak_select_and_preprocess\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "# hacky way to setup logging in jupyter\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.info(\"Setup complete\")\n",
    "\n",
    "\n",
    "def get_p4s_from_part_features(part_features):\n",
    "    \"\"\"Small helper function to get the 4-momentum from part_features.\"\"\"\n",
    "    return ak.zip(\n",
    "        {\n",
    "            \"pt\": part_features.part_pt,\n",
    "            \"eta\": part_features.part_etarel,\n",
    "            \"phi\": part_features.part_phirel,\n",
    "            \"mass\": ak.zeros_like(part_features.part_pt),  # massless particles\n",
    "        },\n",
    "        with_name=\"Momentum4D\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet generation with a trained OmniJet model\n",
    "\n",
    "This notebook provides a short example on how to load a trained OmniJet model\n",
    "with the next-token-prediction head and generate jets with it.\n",
    "\n",
    "For an example on how to reconstruct the generated jets back to physical space, \n",
    "have a look at [the notebook `examples/notebooks/example_tokenize_and_reconstruct_jets.ipynb`](https://github.com/uhh-pd-ml/omnijet_alpha/blob/main/examples/notebooks/example_tokenize_and_reconstruct_jets.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gabbro.models.backbone import BackboneNextTokenPredictionLightning\n",
    "\n",
    "# this checkpoint is the checkpoint from a backbone training with the nex-token-prediction head\n",
    "# make sure you have downloaded the checkpoint in advance\n",
    "# if not, run the script `checkpoints/download_checkpoints.sh`\n",
    "ckpt_path = \"../../checkpoints/generative_8192_tokens/OmniJet_generative_model_UnintentionalPinscher_59.ckpt\"\n",
    "\n",
    "gen_model = BackboneNextTokenPredictionLightning.load_from_checkpoint(ckpt_path)\n",
    "gen_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"/beegfs/desy/user/birkjosc/testing/omnijet/generated_jets.parquet\"\n",
    "generated_jets = gen_model.generate_n_jets_batched(\n",
    "    n_jets=1000,\n",
    "    batch_size=32,\n",
    "    # saveas=save_path,  # use this option if you want to save the awkward array as a parquet file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_jets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct the generated jets back to physical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the tokenizer model from checkpoint, and also get the feature_dict from the config ---\n",
    "\n",
    "from gabbro.models.vqvae import VQVAELightning\n",
    "\n",
    "# this checkpoint is the checkpoint from a tokenization training\n",
    "ckpt_path = \"../../checkpoints/vqvae_8192_tokens/model_ckpt.ckpt\"\n",
    "vqvae_model = VQVAELightning.load_from_checkpoint(ckpt_path)\n",
    "vqvae_model.eval()\n",
    "\n",
    "cfg = OmegaConf.load(Path(ckpt_path).parent / \"config.yaml\")\n",
    "pp_dict = OmegaConf.to_container(cfg.data.dataset_kwargs_common.feature_dict)\n",
    "print(\"\\npp_dict:\")\n",
    "for item in pp_dict:\n",
    "    print(item, pp_dict[item])\n",
    "\n",
    "# get the cuts from the pp_dict (since this leads to particles being removed during\n",
    "# preprocessing/tokenization), thus we also have to remove them from the original jets\n",
    "# when we compare the tokenized+reconstructed particles to the original ones)\n",
    "pp_dict_cuts = {\n",
    "    feat_name: {\n",
    "        criterion: pp_dict[feat_name].get(criterion)\n",
    "        for criterion in [\"larger_than\", \"smaller_than\"]\n",
    "    }\n",
    "    for feat_name in pp_dict\n",
    "}\n",
    "\n",
    "print(\"\\npp_dict_cuts:\")\n",
    "for item in pp_dict_cuts:\n",
    "    print(item, pp_dict_cuts[item])\n",
    "\n",
    "print(\"\\nModel:\")\n",
    "print(vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the generated tokens to physical features\n",
    "\n",
    "# note that if you want to reconstruct tokens from the generative model, you'll have\n",
    "# to remove the start token from the tokenized array, and subtract 1 from the tokens\n",
    "# (since we chose the convention to use 0 as the start token, so the tokens from the\n",
    "# generative model are shifted by 1 compared to the ones from the VQ-VAE)\n",
    "part_features_generated = vqvae_model.reconstruct_ak_tokens(\n",
    "    tokens_ak=generated_jets[:, 1:] - 1,\n",
    "    pp_dict=pp_dict,\n",
    "    batch_size=32,\n",
    "    pad_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gabbro.data.loading import read_jetclass_file\n",
    "\n",
    "n_load = 100_000\n",
    "\n",
    "# --- Load JetClass data ---\n",
    "\n",
    "# change this to the path where you have the JetClass files stored\n",
    "jetclass_file_path_qcd = (\n",
    "    \"/beegfs/desy/user/birkjosc/datasets/jetclass/JetClass/test_20M/ZJetsToNuNu_100.root\"\n",
    ")\n",
    "jetclass_file_path_top = (\n",
    "    \"/beegfs/desy/user/birkjosc/datasets/jetclass/JetClass/test_20M/TTBar_100.root\"\n",
    ")\n",
    "\n",
    "load_kwargs = dict(\n",
    "    particle_features=[\"part_pt\", \"part_etarel\", \"part_phirel\"],\n",
    "    jet_features=None,\n",
    "    labels=None,\n",
    "    n_load=n_load,\n",
    ")\n",
    "part_features_ak_qcd, _, _ = read_jetclass_file(filepath=jetclass_file_path_qcd, **load_kwargs)\n",
    "part_features_ak_qcd = ak_select_and_preprocess(part_features_ak_qcd, pp_dict_cuts)[:, :128]\n",
    "part_features_ak_top, _, _ = read_jetclass_file(filepath=jetclass_file_path_top, **load_kwargs)\n",
    "part_features_ak_top = ak_select_and_preprocess(part_features_ak_top, pp_dict_cuts)[:, :128]\n",
    "\n",
    "# concatenate top and qcd jets from JetClass\n",
    "part_features_ak = ak.concatenate([part_features_ak_qcd, part_features_ak_top], axis=0)\n",
    "\n",
    "# tokenization and reconstruction\n",
    "part_features_ak_tokenized = vqvae_model.tokenize_ak_array(\n",
    "    ak_arr=part_features_ak,\n",
    "    pp_dict=pp_dict,\n",
    "    batch_size=512,\n",
    "    pad_length=128,\n",
    ")\n",
    "part_features_ak_reco = vqvae_model.reconstruct_ak_tokens(\n",
    "    tokens_ak=part_features_ak_tokenized,\n",
    "    pp_dict=pp_dict,\n",
    "    batch_size=512,\n",
    "    pad_length=128,\n",
    ")\n",
    "\n",
    "# plot inclusive jet-level distributions\n",
    "p4s_jetclass = get_p4s_from_part_features(part_features_ak_reco)\n",
    "p4s_jets_jetclass = ak.sum(p4s_jetclass, axis=1)\n",
    "\n",
    "# calculate the substructure\n",
    "jet_substructure_jetclass = JetSubstructure(p4s_jetclass[ak.num(p4s_jetclass) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4s_generated = get_p4s_from_part_features(part_features_generated)\n",
    "p4s_jets_generated = ak.sum(p4s_generated, axis=1)\n",
    "\n",
    "fig, axarr = plot_features(\n",
    "    ak_array_dict={\n",
    "        \"JetClass jets\\n(tokenized+reconstructed)\": p4s_jets_jetclass,\n",
    "        \"Generated jets\": p4s_jets_generated,\n",
    "    },\n",
    "    names={\n",
    "        \"pt\": plot_utils.DEFAULT_LABELS[\"jet_pt\"],\n",
    "        \"eta\": plot_utils.DEFAULT_LABELS[\"jet_eta\"],\n",
    "        \"mass\": plot_utils.DEFAULT_LABELS[\"jet_mass\"],\n",
    "    },\n",
    "    flatten=False,\n",
    "    decorate_ax_kwargs={\"yscale\": 1.7},\n",
    "    bins_dict={\n",
    "        \"pt\": np.linspace(300, 1200, 70),\n",
    "        \"eta\": np.linspace(-0.05, 0.05, 100),\n",
    "        \"mass\": np.linspace(0, 400, 50),\n",
    "    },\n",
    "    # ax_size=(4.2, 3),\n",
    "    legend_kwargs={\"fontsize\": 8},\n",
    ")\n",
    "\n",
    "# particle-level distributions\n",
    "fig, axarr = plot_features(\n",
    "    ak_array_dict={\n",
    "        \"JetClass particles\\n(tokenized+reconstructed)\": p4s_jetclass,\n",
    "        \"Generated particles\": get_p4s_from_part_features(part_features_generated),\n",
    "    },\n",
    "    names={\n",
    "        \"pt\": plot_utils.DEFAULT_LABELS[\"part_pt\"],\n",
    "        \"eta\": plot_utils.DEFAULT_LABELS[\"part_eta\"],\n",
    "        \"phi\": plot_utils.DEFAULT_LABELS[\"part_phi\"],\n",
    "    },\n",
    "    flatten=True,\n",
    "    decorate_ax_kwargs={\"yscale\": 1.7},\n",
    "    bins_dict={\n",
    "        \"pt\": np.linspace(0, 800, 70),\n",
    "        \"eta\": np.linspace(-0.9, 0.9, 70),\n",
    "        \"phi\": np.linspace(-0.9, 0.9, 70),\n",
    "    },\n",
    "    # ax_size=(4.2, 3),\n",
    "    logscale_features=[\"pt\"],\n",
    "    legend_kwargs={\"fontsize\": 8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the substructure\n",
    "from gabbro.metrics.jet_substructure import JetSubstructure\n",
    "\n",
    "jet_substructure_generated = JetSubstructure(p4s_generated[ak.num(p4s_generated) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the substructure\n",
    "fig, axarr = plot_features(\n",
    "    ak_array_dict={\n",
    "        \"JetClass jets\": jet_substructure_jetclass.get_substructure_as_ak_array(),\n",
    "        \"Generated jets\": jet_substructure_generated.get_substructure_as_ak_array(),\n",
    "    },\n",
    "    names=[\"jet_mass\", \"tau32\", \"jet_n_constituents\"],\n",
    "    flatten=False,\n",
    "    # ax_size=(3.5, 3),\n",
    "    legend_kwargs={\"fontsize\": 7, \"ncol\": 2},\n",
    "    decorate_ax_kwargs={\"yscale\": 1.6},\n",
    "    bins_dict={\n",
    "        \"jet_mass\": np.linspace(0, 400, 50),\n",
    "        \"tau32\": np.linspace(0, 1.25, 50),\n",
    "        \"jet_n_constituents\": np.linspace(0.5, 100.5, 51),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
